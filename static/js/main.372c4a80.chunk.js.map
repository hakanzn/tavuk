{"version":3,"sources":["index.js"],"names":["App","videoRef","React","createRef","canvasRef","detectFrame","video","model","detect","then","predictions","_this","renderPredictions","requestAnimationFrame","ctx","current","getContext","clearRect","canvas","width","height","font","textBaseline","forEach","prediction","score","console","log","x","bbox","y","strokeStyle","lineWidth","strokeRect","fillStyle","textWidth","measureText","class","textHeight","parseInt","fillRect","fillText","_this2","this","navigator","mediaDevices","getUserMedia","webCamPromise","audio","facingMode","stream","window","track","getVideoTracks","capabilities","getCapabilities","focusDistance","input","document","querySelector","min","max","step","value","getSettings","oninput","event","applyConstraints","advanced","focusMode","target","srcObject","Promise","resolve","reject","onloadedmetadata","modelPromise","cocoSsd","all","values","catch","error","react__WEBPACK_IMPORTED_MODULE_5___default","a","createElement","className","autoPlay","playsInline","muted","ref","type","Component","rootElement","getElementById","ReactDOM","render"],"mappings":"oOAUMA,0NACJC,SAAWC,IAAMC,cACjBC,UAAYF,IAAMC,cA0DlBE,YAAc,SAACC,EAAOC,GACpBA,EAAMC,OAAOF,GAAOG,KAAK,SAAAC,GAEvBC,EAAKC,kBAAkBF,GACvBG,sBAAsB,WACpBF,EAAKN,YAAYC,EAAOC,UAK9BK,kBAAoB,SAAAF,GAClB,IAAMI,EAAMH,EAAKP,UAAUW,QAAQC,WAAW,MAC9CF,EAAIG,UAAU,EAAG,EAAGH,EAAII,OAAOC,MAAOL,EAAII,OAAOE,QAEjD,IAAMC,EAAO,kBACbP,EAAIO,KAAOA,EACXP,EAAIQ,aAAe,MACnBZ,EAAYa,QAAQ,SAAAC,GAClB,GAAGA,EAAWC,MAAQ,GAAOC,QAAQC,IAAIH,EAAWC,WAApD,CACA,IAAMG,EAAIJ,EAAWK,KAAK,GACpBC,EAAIN,EAAWK,KAAK,GACpBV,EAAQK,EAAWK,KAAK,GACxBT,EAASI,EAAWK,KAAK,GAE/Bf,EAAIiB,YAAc,UAClBjB,EAAIkB,UAAY,EAChBlB,EAAImB,WAAWL,EAAGE,EAAGX,EAAOC,GAE5BN,EAAIoB,UAAY,UAChB,IAAMC,EAAYrB,EAAIsB,YAAYZ,EAAWa,OAAOlB,MAC9CmB,EAAaC,SAASlB,EAAM,IAClCP,EAAI0B,SAASZ,EAAGE,EAAGK,EAAY,EAAGG,EAAa,MAGjD5B,EAAYa,QAAQ,SAAAC,GAClB,IAAMI,EAAIJ,EAAWK,KAAK,GACpBC,EAAIN,EAAWK,KAAK,GAE1Bf,EAAIoB,UAAY,UAChBpB,EAAI2B,SAASjB,EAAWa,MAAOT,EAAGE,yFA/FlB,IAAAY,EAAAC,KAKlB,GAAIC,UAAUC,cAAgBD,UAAUC,aAAaC,aAAc,CACjE,IAAMC,EAAgBH,UAAUC,aAC7BC,aAAa,CACZE,OAAO,EACP1C,MAAO,CACLa,MAAO,KACPC,OAAQ,KACR6B,WAAY,iBAGfxC,KAAK,SAAAyC,GACJC,OAAOD,OAASA,EAGhB,IAAME,EAAQF,EAAOG,iBAAiB,GACrCC,EAAeF,EAAMG,kBAE3B,GAAID,EAAaE,cAAe,CACjC,IAAMC,EAAQC,SAASC,cAAc,uBACrCF,EAAMG,IAAMN,EAAaE,cAAcI,IACvCH,EAAMI,IAAMP,EAAaE,cAAcK,IACvCJ,EAAMK,KAAOR,EAAaE,cAAcM,KACxCL,EAAMM,MAAQX,EAAMY,cAAcR,cAClCC,EAAMQ,QAAU,SAASC,GACzBd,EAAMe,iBAAiB,CACnBC,SAAU,CAAC,CAChBC,UAAW,SACXb,cAAeU,EAAMI,OAAOP,WAOrB,OADArB,EAAKzC,SAASc,QAAQwD,UAAYrB,EAC3B,IAAIsB,QAAQ,SAACC,EAASC,GAC3BhC,EAAKzC,SAASc,QAAQ4D,iBAAmB,WACvCF,SAIFG,EAAeC,MACrBL,QAAQM,IAAI,CAACF,EAAc7B,IACxBtC,KAAK,SAAAsE,GACJrC,EAAKrC,YAAYqC,EAAKzC,SAASc,QAASgE,EAAO,MAEhDC,MAAM,SAAAC,GACLvD,QAAQuD,MAAMA,uCAiDpB,OACEC,EAAAC,EAAAC,cAAA,WACEF,EAAAC,EAAAC,cAAA,SACEC,UAAU,OACVC,UAAQ,EACRC,aAAW,EACXC,OAAK,EACLC,IAAK9C,KAAK1C,SACVkB,MAAM,OACNC,OAAO,SAET8D,EAAAC,EAAAC,cAAA,UACEC,UAAU,OACVI,IAAK9C,KAAKvC,UACVe,MAAM,OACNC,OAAO,SAET8D,EAAAC,EAAAC,cAAA,SACEM,KAAK,kBA1HGxF,IAAMyF,YAiIlBC,EAAclC,SAASmC,eAAe,QAC5CC,IAASC,OAAOb,EAAAC,EAAAC,cAACpF,EAAD,MAAS4F","file":"static/js/main.372c4a80.chunk.js","sourcesContent":["import React from \"react\";\nimport ReactDOM from \"react-dom\";\n\nimport * as cocoSsd from \"@tensorflow-models/coco-ssd\";\nimport  \"@tensorflow/tfjs\";\nimport \"./styles.css\";\n\n\n\n\nclass App extends React.Component {\n  videoRef = React.createRef();\n  canvasRef = React.createRef();\n\n  componentDidMount() {\n \n    //console.log(cocoSsd);\n    \n    \n    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n      const webCamPromise = navigator.mediaDevices\n        .getUserMedia({\n          audio: false,\n          video: {\n            width: 1920,\n            height: 1080,\n            facingMode: \"environment\"\n          }\n        })\n        .then(stream => {\n          window.stream = stream;\n          \n          \n          const track = stream.getVideoTracks()[0];\n  \t  const capabilities = track.getCapabilities();\n  \t   // Map focus distance to a slider element.\n  \t  if (capabilities.focusDistance) {\n\t\t  const input = document.querySelector('input[type=\"range\"]');\n\t\t  input.min = capabilities.focusDistance.min;\n\t\t  input.max = capabilities.focusDistance.max;\n\t\t  input.step = capabilities.focusDistance.step;\n\t\t  input.value = track.getSettings().focusDistance;\n\t\t  input.oninput = function(event) {\n\t\t  track.applyConstraints({\n\t\t      advanced: [{\n\t\t\tfocusMode: \"manual\",\n\t\t\tfocusDistance: event.target.value\n\t\t      }]\n\t\t    });\n\t\t  };\n\t  }\n\t  \n          this.videoRef.current.srcObject = stream;\n          return new Promise((resolve, reject) => {\n            this.videoRef.current.onloadedmetadata = () => {\n              resolve();\n            };\n          });\n        });\n      const modelPromise = cocoSsd.load();\n      Promise.all([modelPromise, webCamPromise])\n        .then(values => {\n          this.detectFrame(this.videoRef.current, values[0]);\n        })\n        .catch(error => {\n          console.error(error);\n        });\n    }\n  }\n\n  detectFrame = (video, model) => {\n    model.detect(video).then(predictions => {\n    \n      this.renderPredictions(predictions);\n      requestAnimationFrame(() => {\n        this.detectFrame(video, model);\n      });\n    });\n  };\n\n  renderPredictions = predictions => {\n    const ctx = this.canvasRef.current.getContext(\"2d\");\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n    // Font options.\n    const font = \"16px sans-serif\";\n    ctx.font = font;\n    ctx.textBaseline = \"top\";\n    predictions.forEach(prediction => {\n      if(prediction.score < 0.80) {console.log(prediction.score);return;}\n      const x = prediction.bbox[0];\n      const y = prediction.bbox[1];\n      const width = prediction.bbox[2];\n      const height = prediction.bbox[3];\n      // Draw the bounding box.\n      ctx.strokeStyle = \"#00FFFF\";\n      ctx.lineWidth = 2;\n      ctx.strokeRect(x, y, width, height);\n      // Draw the label background.\n      ctx.fillStyle = \"#00FFFF\";\n      const textWidth = ctx.measureText(prediction.class).width;\n      const textHeight = parseInt(font, 10); // base 10\n      ctx.fillRect(x, y, textWidth + 4, textHeight + 4);\n    });\n\n    predictions.forEach(prediction => {\n      const x = prediction.bbox[0];\n      const y = prediction.bbox[1];\n      // Draw the text last to ensure it's on top.\n      ctx.fillStyle = \"#000000\";\n      ctx.fillText(prediction.class, x, y);\n    });\n  };\n\n  render() {\n    return (\n      <div>\n        <video\n          className=\"size\"\n          autoPlay\n          playsInline\n          muted\n          ref={this.videoRef}\n          width=\"1080\"\n          height=\"1920\"\n        />\n        <canvas\n          className=\"size\"\n          ref={this.canvasRef}\n          width=\"1080\"\n          height=\"1920\"\n        />\n        <input\n          type=\"range\"\n        />\n      </div>\n    );\n  }\n}\n\nconst rootElement = document.getElementById(\"root\");\nReactDOM.render(<App />, rootElement);\n"],"sourceRoot":""}